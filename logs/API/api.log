[INFO|nodes|L175] 2024-10-07 19:30:28: RAG Generator node : 
 {'date': '2024-10-07 19:27:59', 'question': ['holaaaa', '¿Qué deseas saber o hablar sobre?', '¿Cuál es el tema o asunto que te gustaría discutir o aprender?', '¿Qué tema o área de interés te gustaría explorar o profundizar?', '¿Cuál es el tema o área de interés que deseas investigar o aprender más sobre?', '¿Qué tema o área de estudio te gustaría explorar o profundizar en?', '¿Cuál es el campo de estudio o área de interés que deseas investigar o dominar?', '¿Cuál es el tema o disciplina que te gustaría explorar o especializarte en?', '¿Cuál área de estudio o campo profesional te interesa investigar o dominar?'], 'query_label': 'Otra', 'generation': "I don't know. The provided context is about the creation of a Viceconsulate in El Calafate, Argentina, and its jurisdiction, which doesn't relate to a specific theme or discipline that I'd like to explore or specialize in.", 'documents': [Document(id='295986df-90f4-44c8-b307-a1f89c00d7ce', metadata={'chunk_id': '6ef44726-eb2d-5d1a-94b0-8cc3da0b7054', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '13', '40']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 625.0, 'num_tokens': 164.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='La creación de este Viceconsulado Honorario facilitará la atención de casos urgentes de protección y asistencia consular en El Calafate. Tendrá su sede en esta ciudad y su circunscripción consular abarcará los departamentos de Lago Argentino y Río Chico en la provincia de Santa Cruz. En consecuencia, es preciso modificar la circunscripción de los Viceconsulados Honorarios de Río Gallegos y de Puerto San Julián para que abarquen, el primero, los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos ellos en la provincia de Santa Cruz. Verificable en  '), Document(id='e8be5ab8-728e-417b-a901-583d28bc45e9', metadata={'chunk_id': '2b180d68-0892-5c73-a393-a9087a0e88fd', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '26', '25']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 109.0, 'num_tokens': 33.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='# Artículo 1. Creación de la Oficina Consular honoraria en El Calafate y delimitación de su circunscripción. ')], 'fact_based_answer': 'reprocess_query', 'useful_answer': None}
[INFO|chains|L31] 2024-10-07 19:30:28: Initializing LangChain using : get_groq
[INFO|_client|L1038] 2024-10-07 19:30:29: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO|_base_client|L1067] 2024-10-07 19:30:29: Retrying request to /openai/v1/chat/completions in 2.000000 seconds
[INFO|_client|L1038] 2024-10-07 19:30:31: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO|nodes|L196] 2024-10-07 19:30:31: RAG Context : 
 La creación de este Viceconsulado Honorario facilitará la atención de casos urgentes de protección y asistencia consular en El Calafate. Tendrá su sede en esta ciudad y su circunscripción consular abarcará los departamentos de Lago Argentino y Río Chico en la provincia de Santa Cruz. En consecuencia, es preciso modificar la circunscripción de los Viceconsulados Honorarios de Río Gallegos y de Puerto San Julián para que abarquen, el primero, los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos ellos en la provincia de Santa Cruz. Verificable en  

# Artículo 1. Creación de la Oficina Consular honoraria en El Calafate y delimitación de su circunscripción. 
[INFO|nodes|L197] 2024-10-07 19:30:31: RAG Question : 
 ¿Cuál área de estudio o campo profesional te interesa investigar o dominar?
[INFO|nodes|L198] 2024-10-07 19:30:31: RAG Response : 
 I don't know.
[INFO|nodes|L237] 2024-10-07 19:30:31: hallucination_checker node : 
 {'date': '2024-10-07 19:27:59', 'question': ['holaaaa', '¿Qué deseas saber o hablar sobre?', '¿Cuál es el tema o asunto que te gustaría discutir o aprender?', '¿Qué tema o área de interés te gustaría explorar o profundizar?', '¿Cuál es el tema o área de interés que deseas investigar o aprender más sobre?', '¿Qué tema o área de estudio te gustaría explorar o profundizar en?', '¿Cuál es el campo de estudio o área de interés que deseas investigar o dominar?', '¿Cuál es el tema o disciplina que te gustaría explorar o especializarte en?', '¿Cuál área de estudio o campo profesional te interesa investigar o dominar?'], 'query_label': 'Otra', 'generation': "I don't know.", 'documents': [Document(id='295986df-90f4-44c8-b307-a1f89c00d7ce', metadata={'chunk_id': '6ef44726-eb2d-5d1a-94b0-8cc3da0b7054', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '13', '40']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 625.0, 'num_tokens': 164.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='La creación de este Viceconsulado Honorario facilitará la atención de casos urgentes de protección y asistencia consular en El Calafate. Tendrá su sede en esta ciudad y su circunscripción consular abarcará los departamentos de Lago Argentino y Río Chico en la provincia de Santa Cruz. En consecuencia, es preciso modificar la circunscripción de los Viceconsulados Honorarios de Río Gallegos y de Puerto San Julián para que abarquen, el primero, los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos ellos en la provincia de Santa Cruz. Verificable en  '), Document(id='e8be5ab8-728e-417b-a901-583d28bc45e9', metadata={'chunk_id': '2b180d68-0892-5c73-a393-a9087a0e88fd', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '26', '25']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 109.0, 'num_tokens': 33.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='# Artículo 1. Creación de la Oficina Consular honoraria en El Calafate y delimitación de su circunscripción. ')], 'fact_based_answer': 'reprocess_query', 'useful_answer': None}
[WARNING|nodes|L251] 2024-10-07 19:30:31: Generator LLM says I don't know., founded coincidencias=["don't", 'know'] -> need requery
[INFO|nodes|L356] 2024-10-07 19:30:31: Router Generation or Grader Generation : 
 {'fact_based_answer': 'reprocess_query', 'date': '2024-10-07 19:27:59', 'question': ['holaaaa', '¿Qué deseas saber o hablar sobre?', '¿Cuál es el tema o asunto que te gustaría discutir o aprender?', '¿Qué tema o área de interés te gustaría explorar o profundizar?', '¿Cuál es el tema o área de interés que deseas investigar o aprender más sobre?', '¿Qué tema o área de estudio te gustaría explorar o profundizar en?', '¿Cuál es el campo de estudio o área de interés que deseas investigar o dominar?', '¿Cuál es el tema o disciplina que te gustaría explorar o especializarte en?', '¿Cuál área de estudio o campo profesional te interesa investigar o dominar?'], 'query_label': 'Otra', 'generation': "I don't know.", 'documents': [Document(id='295986df-90f4-44c8-b307-a1f89c00d7ce', metadata={'chunk_id': '6ef44726-eb2d-5d1a-94b0-8cc3da0b7054', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '13', '40']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 625.0, 'num_tokens': 164.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='La creación de este Viceconsulado Honorario facilitará la atención de casos urgentes de protección y asistencia consular en El Calafate. Tendrá su sede en esta ciudad y su circunscripción consular abarcará los departamentos de Lago Argentino y Río Chico en la provincia de Santa Cruz. En consecuencia, es preciso modificar la circunscripción de los Viceconsulados Honorarios de Río Gallegos y de Puerto San Julián para que abarquen, el primero, los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos ellos en la provincia de Santa Cruz. Verificable en  '), Document(id='e8be5ab8-728e-417b-a901-583d28bc45e9', metadata={'chunk_id': '2b180d68-0892-5c73-a393-a9087a0e88fd', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '26', '25']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 109.0, 'num_tokens': 33.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='# Artículo 1. Creación de la Oficina Consular honoraria en El Calafate y delimitación de su circunscripción. ')], 'useful_answer': None}
[INFO|nodes|L369] 2024-10-07 19:30:31: Routing to -> 'reprocess_query'
[INFO|nodes|L213] 2024-10-07 19:30:31: Query Processing : 
 {'date': '2024-10-07 19:27:59', 'question': ['holaaaa', '¿Qué deseas saber o hablar sobre?', '¿Cuál es el tema o asunto que te gustaría discutir o aprender?', '¿Qué tema o área de interés te gustaría explorar o profundizar?', '¿Cuál es el tema o área de interés que deseas investigar o aprender más sobre?', '¿Qué tema o área de estudio te gustaría explorar o profundizar en?', '¿Cuál es el campo de estudio o área de interés que deseas investigar o dominar?', '¿Cuál es el tema o disciplina que te gustaría explorar o especializarte en?', '¿Cuál área de estudio o campo profesional te interesa investigar o dominar?'], 'query_label': 'Otra', 'generation': "I don't know.", 'documents': [Document(id='295986df-90f4-44c8-b307-a1f89c00d7ce', metadata={'chunk_id': '6ef44726-eb2d-5d1a-94b0-8cc3da0b7054', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '13', '40']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 625.0, 'num_tokens': 164.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='La creación de este Viceconsulado Honorario facilitará la atención de casos urgentes de protección y asistencia consular en El Calafate. Tendrá su sede en esta ciudad y su circunscripción consular abarcará los departamentos de Lago Argentino y Río Chico en la provincia de Santa Cruz. En consecuencia, es preciso modificar la circunscripción de los Viceconsulados Honorarios de Río Gallegos y de Puerto San Julián para que abarquen, el primero, los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos ellos en la provincia de Santa Cruz. Verificable en  '), Document(id='e8be5ab8-728e-417b-a901-583d28bc45e9', metadata={'chunk_id': '2b180d68-0892-5c73-a393-a9087a0e88fd', 'cluster_summary': 'Se crea un Viceconsulado Honorario en El Calafate para atender casos urgentes de protección y asistencia consular. Su sede estará en esta ciudad y su circunscripción abarcará los departamentos de Lago Argentino y Río Chico, en la provincia de Santa Cruz. Se modifican las circunscripciones de los Viceconsulados Honorarios de Río Gallegos y Puerto San Julián: el primero abarcará los departamentos de Güer Aike y Corpen Aike, y el segundo los departamentos de Lago Buenos Aires, Deseado y Magallanes, todos en la provincia de Santa Cruz.', 'creation_date': '2024-10-02', 'fecha_publicacion_boe': 'data-boe-uploads', 'file_name': 'BOE-A-2024-7293.pdf', 'file_path': 'C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\data\\boe\\uploads\\BOE-A-2024-7293.pdf', 'file_size': 202785.0, 'file_type': 'application/pdf', 'label': "['2', '26', '25']", 'label_str': 'Tratados y Convenios Internacionales', 'last_modified_date': '2024-10-02', 'ministerios': '[]', 'num_caracteres': 109.0, 'num_tokens': 33.0, 'orden': "['Orden AUC/319/2024']", 'pdf_id': '13d91cbf-7cef-48ad-9c68-f12bcf2b6118', 'real_decreto': "['Real Decreto 1390/2007']"}, page_content='# Artículo 1. Creación de la Oficina Consular honoraria en El Calafate y delimitación de su circunscripción. ')], 'fact_based_answer': 'reprocess_query', 'useful_answer': None}
[INFO|chains|L31] 2024-10-07 19:30:31: Initializing LangChain using : get_groq
[INFO|_client|L1038] 2024-10-07 19:30:32: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
[INFO|_base_client|L1067] 2024-10-07 19:30:32: Retrying request to /openai/v1/chat/completions in 2.000000 seconds
[INFO|_client|L1038] 2024-10-07 19:30:34: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
[INFO|nodes|L227] 2024-10-07 19:30:34: question='¿Cuál área de estudio o campo profesional te interesa investigar o dominar?' // after reprocessing question -> response='¿Cuál es el área de especialización o carrera que deseas explorar o desarrollar?'
[INFO|_client|L1038] 2024-10-07 19:30:35: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : 
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : 
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : ¡
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : ¡
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : Hola
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : Hola
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : !
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : !
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  ¿
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  ¿
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : En
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : En
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  qué
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  qué
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  puedo
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  puedo
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  ayudarte
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  ayudarte
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  hoy
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  hoy
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  con
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  con
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  respecto
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  respecto
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  al
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  al
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  Bo
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  Bo
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : let
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : let
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : ín
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : ín
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  Oficial
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  Oficial
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  del
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  del
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  Estado
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  Estado
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  Español
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  Español
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  (
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  (
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : BO
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : BO
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : E
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : E
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : )?
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : )?
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  Si
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  Si
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  tienes
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  tienes
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  alguna
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  alguna
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  pregunta
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  pregunta
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  específica
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  específica
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : ,
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : ,
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  no
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  no
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  dudes
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  dudes
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  en
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  en
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content :  dec
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content :  dec
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : í
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : í
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : rm
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : rm
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : elo
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : elo
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : .
[INFO|openai_api|L124] 2024-10-07 19:30:35: event.choices[0].delta.content : .
[INFO|openai_api|L119] 2024-10-07 19:30:35: event.choices[0].delta.content : None
[INFO|openai_api|L137] 2024-10-07 19:30:35: complete message :  ¡Hola! ¿En qué puedo ayudarte hoy con respecto al Boletín Oficial del Estado Español (BOE)? Si tienes alguna pregunta específica, no dudes en decírmelo.
[INFO|main|L65] 2024-10-07 19:31:58: Getting Graph configuration from CONFIG_PATH='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json'
[INFO|config|L93] 2024-10-07 19:31:58: Definida configuracion mediante archivo JSON en C:\Users\Jorge\Desktop\Boe ChatBot\backend\src\..\config/graph\graph.json
[INFO|config|L224] 2024-10-07 19:31:58: Agent query_classificator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-07 19:31:58: Agent docs_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-07 19:31:58: Agent query_processor -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-07 19:31:58: Agent generator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-07 19:31:58: Agent hallucination_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-07 19:31:58: Agent answer_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L150] 2024-10-07 19:31:58: Graph Agents : {'query_classificator': Agent(agent_name='query_classificator', model='GROQ', get_model=<function get_groq at 0x00000208FF9C3BA0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['labels', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['labels'], input_types={}, partial_variables={}, template="You are an assistant specialized in categorizing a text from the Spanish Boletín Oficial del Estado (BOE).\n\n            Your task is to classify the provided text using the specified list of labels. The possible labels are: {labels}\n\n            If the text does not belong to a label, classify it as 'Otra'. Provide the label with no preamble or explanation"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'docs_grader': Agent(agent_name='docs_grader', model='GROQ', get_model=<function get_groq at 0x00000208FF9C3BA0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template="You are an AI model designed grade the relevance of a retrieved document to a user question.\n\n                If the document contains keywords related to the user question, grade it as relevant.\n\n                Give a binary score of 'yes' or 'no' to indicate whether the document is relevant to the question. \n\n                Provide the binary score with no explanation.\n\n                Here is the retrieved document: {document} "), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'query_processor': Agent(agent_name='query_processor', model='GROQ', get_model=<function get_groq at 0x00000208FF9C3BA0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a question re-writer that converts an input question to a better version that is optimized for vectorstore retrieval. \n\n                    Look at the input and try to reason about the underlying semantic intent / meaning.\n\n                    Provide the reprocessed question in spanish with no preamble or explanation'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'generator': Agent(agent_name='generator', model='GROQ', get_model=<function get_groq at 0x00000208FF9C3BA0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template="You are an assistant for question-answering tasks.\n\n                    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'I you don't know'.\n\n                    Use three sentences maximum and keep the answer concise.\n\n                    Context:\n{context}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'hallucination_grader': Agent(agent_name='hallucination_grader', model='GROQ', get_model=<function get_groq at 0x00000208FF9C3BA0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['documents', 'generation'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents'], input_types={}, partial_variables={}, template="You are a grader assessing whether an answer is grounded in / supported by a set of facts. \n \n                Give a binary score 'yes' or 'no' score to indicate\n\n                whether the answer is grounded in or supported by a set of facts. Provide the binary score with no preamble or explanation.\n\n                Here are the facts:\n{documents}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'answer_grader': Agent(agent_name='answer_grader', model='GROQ', get_model=<function get_groq at 0x00000208FF9C3BA0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['generation', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template="You are a grader assessing whether an  answer is useful to resolve a question.\n\n                Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.\n\n                Provide the binary score with no preamble or explanation.\n                Here is the question:\n{question}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>)}
[INFO|config|L229] 2024-10-07 19:31:58: Connecting to an existing index of PineCone DB cient
[INFO|discover_namespace_packages|L12] 2024-10-07 19:31:58: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-07 19:31:58: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-07 19:31:58: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-07 19:31:58: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-07 19:31:58: Installing plugin inference into Pinecone
[INFO|config|L236] 2024-10-07 19:31:59: existing_indexes : ['boe']
[INFO|SentenceTransformer|L196] 2024-10-07 19:31:59: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-07 19:31:59: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|main|L67] 2024-10-07 19:32:01: config_graph : ConfigGraph(config_path='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json', graph=None, compile_graph=None)
[INFO|main|L69] 2024-10-07 19:32:01: Creating graph and compiling workflow...
[INFO|main|L81] 2024-10-07 19:32:01: Graph and workflow created
[INFO|SentenceTransformer|L196] 2024-10-07 19:32:03: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-07 19:32:03: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|SentenceTransformer|L196] 2024-10-07 19:32:05: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-07 19:32:05: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|raptor_vectordb|L35] 2024-10-07 19:32:07: Connecting to an existing index of PineCone DB cient -> boe
[INFO|discover_namespace_packages|L12] 2024-10-07 19:32:07: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-07 19:32:07: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-07 19:32:07: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-07 19:32:07: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-07 19:32:07: Installing plugin inference into Pinecone
[INFO|raptor_vectordb|L40] 2024-10-07 19:32:08: existing_indexes : ['boe']
[INFO|main|L65] 2024-10-08 21:07:42: Getting Graph configuration from CONFIG_PATH='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json'
[INFO|config|L93] 2024-10-08 21:07:42: Definida configuracion mediante archivo JSON en C:\Users\Jorge\Desktop\Boe ChatBot\backend\src\..\config/graph\graph.json
[INFO|config|L224] 2024-10-08 21:07:42: Agent query_classificator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-08 21:07:43: Agent docs_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-08 21:07:43: Agent query_processor -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-08 21:07:43: Agent generator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-08 21:07:43: Agent hallucination_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-08 21:07:43: Agent answer_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L150] 2024-10-08 21:07:43: Graph Agents : {'query_classificator': Agent(agent_name='query_classificator', model='GROQ', get_model=<function get_groq at 0x000002390AFA3CE0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['labels', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['labels'], input_types={}, partial_variables={}, template="You are an assistant specialized in categorizing a text from the Spanish Boletín Oficial del Estado (BOE).\n\n            Your task is to classify the provided text using the specified list of labels. The possible labels are: {labels}\n\n            If the text does not belong to a label, classify it as 'Otra'. Provide the label with no preamble or explanation"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'docs_grader': Agent(agent_name='docs_grader', model='GROQ', get_model=<function get_groq at 0x000002390AFA3CE0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template="You are an AI model designed grade the relevance of a retrieved document to a user question.\n\n                If the document contains keywords related to the user question, grade it as relevant.\n\n                Give a binary score of 'yes' or 'no' to indicate whether the document is relevant to the question. \n\n                Provide the binary score with no explanation.\n\n                Here is the retrieved document: {document} "), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'query_processor': Agent(agent_name='query_processor', model='GROQ', get_model=<function get_groq at 0x000002390AFA3CE0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a question re-writer that converts an input question to a better version that is optimized for vectorstore retrieval. \n\n                    Look at the input and try to reason about the underlying semantic intent / meaning.\n\n                    Provide the reprocessed question in spanish with no preamble or explanation'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'generator': Agent(agent_name='generator', model='GROQ', get_model=<function get_groq at 0x000002390AFA3CE0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template="You are an assistant for question-answering tasks.\n\n                    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'I you don't know'.\n\n                    Use three sentences maximum and keep the answer concise.\n\n                    Context:\n{context}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'hallucination_grader': Agent(agent_name='hallucination_grader', model='GROQ', get_model=<function get_groq at 0x000002390AFA3CE0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['documents', 'generation'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents'], input_types={}, partial_variables={}, template="You are a grader assessing whether an answer is grounded in / supported by a set of facts. \n \n                Give a binary score 'yes' or 'no' score to indicate\n\n                whether the answer is grounded in or supported by a set of facts. Provide the binary score with no preamble or explanation.\n\n                Here are the facts:\n{documents}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'answer_grader': Agent(agent_name='answer_grader', model='GROQ', get_model=<function get_groq at 0x000002390AFA3CE0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['generation', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template="You are a grader assessing whether an  answer is useful to resolve a question.\n\n                Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.\n\n                Provide the binary score with no preamble or explanation.\n                Here is the question:\n{question}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>)}
[INFO|config|L229] 2024-10-08 21:07:43: Connecting to an existing index of PineCone DB cient
[INFO|discover_namespace_packages|L12] 2024-10-08 21:07:43: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-08 21:07:43: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-08 21:07:43: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-08 21:07:43: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-08 21:07:43: Installing plugin inference into Pinecone
[INFO|config|L236] 2024-10-08 21:07:43: existing_indexes : ['boe']
[INFO|SentenceTransformer|L196] 2024-10-08 21:07:43: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-08 21:07:43: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|main|L67] 2024-10-08 21:07:45: config_graph : ConfigGraph(config_path='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json', graph=None, compile_graph=None)
[INFO|main|L69] 2024-10-08 21:07:45: Creating graph and compiling workflow...
[INFO|main|L81] 2024-10-08 21:07:45: Graph and workflow created
[INFO|SentenceTransformer|L196] 2024-10-08 21:07:47: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-08 21:07:47: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|SentenceTransformer|L196] 2024-10-08 21:07:49: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-08 21:07:49: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|raptor_vectordb|L35] 2024-10-08 21:07:51: Connecting to an existing index of PineCone DB cient -> boe
[INFO|discover_namespace_packages|L12] 2024-10-08 21:07:51: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-08 21:07:51: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-08 21:07:51: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-08 21:07:51: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-08 21:07:51: Installing plugin inference into Pinecone
[INFO|raptor_vectordb|L40] 2024-10-08 21:07:52: existing_indexes : ['boe']
[INFO|main|L65] 2024-10-11 15:43:22: Getting Graph configuration from CONFIG_PATH='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json'
[INFO|config|L93] 2024-10-11 15:43:22: Definida configuracion mediante archivo JSON en C:\Users\Jorge\Desktop\Boe ChatBot\backend\src\..\config/graph\graph.json
[INFO|config|L224] 2024-10-11 15:43:22: Agent query_classificator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:43:22: Agent docs_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:43:22: Agent query_processor -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:43:22: Agent generator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:43:22: Agent hallucination_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:43:22: Agent answer_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L150] 2024-10-11 15:43:22: Graph Agents : {'query_classificator': Agent(agent_name='query_classificator', model='GROQ', get_model=<function get_groq at 0x0000020025C1ED40>, temperature=0, prompt=ChatPromptTemplate(input_variables=['labels', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['labels'], input_types={}, partial_variables={}, template="You are an assistant specialized in categorizing a text from the Spanish Boletín Oficial del Estado (BOE).\n\n            Your task is to classify the provided text using the specified list of labels. The possible labels are: {labels}\n\n            If the text does not belong to a label, classify it as 'Otra'. Provide the label with no preamble or explanation"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'docs_grader': Agent(agent_name='docs_grader', model='GROQ', get_model=<function get_groq at 0x0000020025C1ED40>, temperature=0, prompt=ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template="You are an AI model designed grade the relevance of a retrieved document to a user question.\n\n                If the document contains keywords related to the user question, grade it as relevant.\n\n                Give a binary score of 'yes' or 'no' to indicate whether the document is relevant to the question. \n\n                Provide the binary score with no explanation.\n\n                Here is the retrieved document: {document} "), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'query_processor': Agent(agent_name='query_processor', model='GROQ', get_model=<function get_groq at 0x0000020025C1ED40>, temperature=0, prompt=ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a question re-writer that converts an input question to a better version that is optimized for vectorstore retrieval. \n\n                    Look at the input and try to reason about the underlying semantic intent / meaning.\n\n                    Provide the reprocessed question in spanish with no preamble or explanation'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'generator': Agent(agent_name='generator', model='GROQ', get_model=<function get_groq at 0x0000020025C1ED40>, temperature=0, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template="You are an assistant for question-answering tasks.\n\n                    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'I you don't know'.\n\n                    Use three sentences maximum and keep the answer concise.\n\n                    Context:\n{context}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'hallucination_grader': Agent(agent_name='hallucination_grader', model='GROQ', get_model=<function get_groq at 0x0000020025C1ED40>, temperature=0, prompt=ChatPromptTemplate(input_variables=['documents', 'generation'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents'], input_types={}, partial_variables={}, template="You are a grader assessing whether an answer is grounded in / supported by a set of facts. \n \n                Give a binary score 'yes' or 'no' score to indicate\n\n                whether the answer is grounded in or supported by a set of facts. Provide the binary score with no preamble or explanation.\n\n                Here are the facts:\n{documents}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'answer_grader': Agent(agent_name='answer_grader', model='GROQ', get_model=<function get_groq at 0x0000020025C1ED40>, temperature=0, prompt=ChatPromptTemplate(input_variables=['generation', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template="You are a grader assessing whether an  answer is useful to resolve a question.\n\n                Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.\n\n                Provide the binary score with no preamble or explanation.\n                Here is the question:\n{question}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>)}
[INFO|config|L229] 2024-10-11 15:43:22: Connecting to an existing index of PineCone DB cient
[INFO|discover_namespace_packages|L12] 2024-10-11 15:43:22: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-11 15:43:22: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-11 15:43:22: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-11 15:43:22: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-11 15:43:22: Installing plugin inference into Pinecone
[INFO|config|L236] 2024-10-11 15:43:23: existing_indexes : ['boe']
[INFO|SentenceTransformer|L196] 2024-10-11 15:43:24: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:43:24: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|main|L67] 2024-10-11 15:43:26: config_graph : ConfigGraph(config_path='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json', graph=None, compile_graph=None)
[INFO|main|L69] 2024-10-11 15:43:26: Creating graph and compiling workflow...
[INFO|main|L81] 2024-10-11 15:43:26: Graph and workflow created
[INFO|SentenceTransformer|L196] 2024-10-11 15:43:30: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:43:30: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|SentenceTransformer|L196] 2024-10-11 15:43:33: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:43:33: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|raptor_vectordb|L35] 2024-10-11 15:43:36: Connecting to an existing index of PineCone DB cient -> boe
[INFO|discover_namespace_packages|L12] 2024-10-11 15:43:36: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-11 15:43:36: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-11 15:43:36: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-11 15:43:36: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-11 15:43:36: Installing plugin inference into Pinecone
[INFO|raptor_vectordb|L40] 2024-10-11 15:43:37: existing_indexes : ['boe']
[INFO|main|L66] 2024-10-11 15:44:38: Getting Graph configuration from CONFIG_PATH='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json'
[INFO|config|L93] 2024-10-11 15:44:38: Definida configuracion mediante archivo JSON en C:\Users\Jorge\Desktop\Boe ChatBot\backend\src\..\config/graph\graph.json
[INFO|config|L224] 2024-10-11 15:44:38: Agent query_classificator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:44:38: Agent docs_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:44:38: Agent query_processor -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:44:38: Agent generator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:44:38: Agent hallucination_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:44:38: Agent answer_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L150] 2024-10-11 15:44:38: Graph Agents : {'query_classificator': Agent(agent_name='query_classificator', model='GROQ', get_model=<function get_groq at 0x0000022CF31400E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['labels', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['labels'], input_types={}, partial_variables={}, template="You are an assistant specialized in categorizing a text from the Spanish Boletín Oficial del Estado (BOE).\n\n            Your task is to classify the provided text using the specified list of labels. The possible labels are: {labels}\n\n            If the text does not belong to a label, classify it as 'Otra'. Provide the label with no preamble or explanation"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'docs_grader': Agent(agent_name='docs_grader', model='GROQ', get_model=<function get_groq at 0x0000022CF31400E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template="You are an AI model designed grade the relevance of a retrieved document to a user question.\n\n                If the document contains keywords related to the user question, grade it as relevant.\n\n                Give a binary score of 'yes' or 'no' to indicate whether the document is relevant to the question. \n\n                Provide the binary score with no explanation.\n\n                Here is the retrieved document: {document} "), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'query_processor': Agent(agent_name='query_processor', model='GROQ', get_model=<function get_groq at 0x0000022CF31400E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a question re-writer that converts an input question to a better version that is optimized for vectorstore retrieval. \n\n                    Look at the input and try to reason about the underlying semantic intent / meaning.\n\n                    Provide the reprocessed question in spanish with no preamble or explanation'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'generator': Agent(agent_name='generator', model='GROQ', get_model=<function get_groq at 0x0000022CF31400E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template="You are an assistant for question-answering tasks.\n\n                    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'I you don't know'.\n\n                    Use three sentences maximum and keep the answer concise.\n\n                    Context:\n{context}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'hallucination_grader': Agent(agent_name='hallucination_grader', model='GROQ', get_model=<function get_groq at 0x0000022CF31400E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['documents', 'generation'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents'], input_types={}, partial_variables={}, template="You are a grader assessing whether an answer is grounded in / supported by a set of facts. \n \n                Give a binary score 'yes' or 'no' score to indicate\n\n                whether the answer is grounded in or supported by a set of facts. Provide the binary score with no preamble or explanation.\n\n                Here are the facts:\n{documents}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'answer_grader': Agent(agent_name='answer_grader', model='GROQ', get_model=<function get_groq at 0x0000022CF31400E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['generation', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template="You are a grader assessing whether an  answer is useful to resolve a question.\n\n                Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.\n\n                Provide the binary score with no preamble or explanation.\n                Here is the question:\n{question}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>)}
[INFO|config|L229] 2024-10-11 15:44:38: Connecting to an existing index of PineCone DB cient
[INFO|discover_namespace_packages|L12] 2024-10-11 15:44:38: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-11 15:44:38: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-11 15:44:38: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-11 15:44:38: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-11 15:44:38: Installing plugin inference into Pinecone
[INFO|config|L236] 2024-10-11 15:44:39: existing_indexes : ['boe']
[INFO|SentenceTransformer|L196] 2024-10-11 15:44:40: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:44:40: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|main|L68] 2024-10-11 15:44:43: config_graph : ConfigGraph(config_path='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json', graph=None, compile_graph=None)
[INFO|main|L70] 2024-10-11 15:44:43: Creating graph and compiling workflow...
[INFO|main|L82] 2024-10-11 15:44:43: Graph and workflow created
[INFO|SentenceTransformer|L196] 2024-10-11 15:44:47: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:44:47: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|SentenceTransformer|L196] 2024-10-11 15:44:50: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:44:50: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|raptor_vectordb|L35] 2024-10-11 15:44:53: Connecting to an existing index of PineCone DB cient -> boe
[INFO|discover_namespace_packages|L12] 2024-10-11 15:44:53: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-11 15:44:53: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-11 15:44:53: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-11 15:44:53: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-11 15:44:53: Installing plugin inference into Pinecone
[INFO|raptor_vectordb|L40] 2024-10-11 15:44:54: existing_indexes : ['boe']
[INFO|main|L66] 2024-10-11 15:48:04: Getting Graph configuration from CONFIG_PATH='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json'
[INFO|config|L93] 2024-10-11 15:48:04: Definida configuracion mediante archivo JSON en C:\Users\Jorge\Desktop\Boe ChatBot\backend\src\..\config/graph\graph.json
[INFO|config|L224] 2024-10-11 15:48:04: Agent query_classificator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:48:04: Agent docs_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:48:04: Agent query_processor -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:48:04: Agent generator -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:48:04: Agent hallucination_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L224] 2024-10-11 15:48:04: Agent answer_grader -> Parser <class 'langchain_core.output_parsers.string.StrOutputParser'>
[INFO|config|L150] 2024-10-11 15:48:04: Graph Agents : {'query_classificator': Agent(agent_name='query_classificator', model='GROQ', get_model=<function get_groq at 0x000001EA4E1100E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['labels', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['labels'], input_types={}, partial_variables={}, template="You are an assistant specialized in categorizing a text from the Spanish Boletín Oficial del Estado (BOE).\n\n            Your task is to classify the provided text using the specified list of labels. The possible labels are: {labels}\n\n            If the text does not belong to a label, classify it as 'Otra'. Provide the label with no preamble or explanation"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'docs_grader': Agent(agent_name='docs_grader', model='GROQ', get_model=<function get_groq at 0x000001EA4E1100E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document'], input_types={}, partial_variables={}, template="You are an AI model designed grade the relevance of a retrieved document to a user question.\n\n                If the document contains keywords related to the user question, grade it as relevant.\n\n                Give a binary score of 'yes' or 'no' to indicate whether the document is relevant to the question. \n\n                Provide the binary score with no explanation.\n\n                Here is the retrieved document: {document} "), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'query_processor': Agent(agent_name='query_processor', model='GROQ', get_model=<function get_groq at 0x000001EA4E1100E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a question re-writer that converts an input question to a better version that is optimized for vectorstore retrieval. \n\n                    Look at the input and try to reason about the underlying semantic intent / meaning.\n\n                    Provide the reprocessed question in spanish with no preamble or explanation'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'generator': Agent(agent_name='generator', model='GROQ', get_model=<function get_groq at 0x000001EA4E1100E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template="You are an assistant for question-answering tasks.\n\n                    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'I you don't know'.\n\n                    Use three sentences maximum and keep the answer concise.\n\n                    Context:\n{context}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'hallucination_grader': Agent(agent_name='hallucination_grader', model='GROQ', get_model=<function get_groq at 0x000001EA4E1100E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['documents', 'generation'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents'], input_types={}, partial_variables={}, template="You are a grader assessing whether an answer is grounded in / supported by a set of facts. \n \n                Give a binary score 'yes' or 'no' score to indicate\n\n                whether the answer is grounded in or supported by a set of facts. Provide the binary score with no preamble or explanation.\n\n                Here are the facts:\n{documents}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>), 'answer_grader': Agent(agent_name='answer_grader', model='GROQ', get_model=<function get_groq at 0x000001EA4E1100E0>, temperature=0, prompt=ChatPromptTemplate(input_variables=['generation', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template="You are a grader assessing whether an  answer is useful to resolve a question.\n\n                Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.\n\n                Provide the binary score with no preamble or explanation.\n                Here is the question:\n{question}\n"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['generation'], input_types={}, partial_variables={}, template='{generation}'), additional_kwargs={})]), parser=<class 'langchain_core.output_parsers.string.StrOutputParser'>)}
[INFO|config|L229] 2024-10-11 15:48:04: Connecting to an existing index of PineCone DB cient
[INFO|discover_namespace_packages|L12] 2024-10-11 15:48:04: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-11 15:48:04: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-11 15:48:04: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-11 15:48:05: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-11 15:48:05: Installing plugin inference into Pinecone
[INFO|config|L236] 2024-10-11 15:48:05: existing_indexes : ['boe']
[INFO|SentenceTransformer|L196] 2024-10-11 15:48:06: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:48:06: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|main|L68] 2024-10-11 15:48:09: config_graph : ConfigGraph(config_path='C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\src\\..\\config/graph\\graph.json', graph=None, compile_graph=None)
[INFO|main|L70] 2024-10-11 15:48:09: Creating graph and compiling workflow...
[INFO|main|L82] 2024-10-11 15:48:09: Graph and workflow created
[INFO|SentenceTransformer|L196] 2024-10-11 15:48:13: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:48:13: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|SentenceTransformer|L196] 2024-10-11 15:48:16: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L204] 2024-10-11 15:48:16: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[INFO|raptor_vectordb|L35] 2024-10-11 15:48:18: Connecting to an existing index of PineCone DB cient -> boe
[INFO|discover_namespace_packages|L12] 2024-10-11 15:48:18: Discovering subpackages in _NamespacePath(['C:\\Users\\Jorge\\Desktop\\Boe ChatBot\\backend\\env\\Lib\\site-packages\\pinecone_plugins'])
[INFO|discover_plugins|L9] 2024-10-11 15:48:18: Looking for plugins in pinecone_plugins.assistant
[INFO|discover_plugins|L9] 2024-10-11 15:48:18: Looking for plugins in pinecone_plugins.inference
[INFO|installation|L10] 2024-10-11 15:48:18: Installing plugin assistant into Pinecone
[INFO|installation|L10] 2024-10-11 15:48:18: Installing plugin inference into Pinecone
[INFO|raptor_vectordb|L40] 2024-10-11 15:48:19: existing_indexes : ['boe']
